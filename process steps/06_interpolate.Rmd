---
title: "Interpolate VMS Data"
output: html_document
---

## Purpose

In this step, we produce a version of the VMS data that is interpolated such that records are evenly distributed every hour.

First, the script filters for time gaps over which it is unlikely that linear interpolation will be representative. According to the following rules:

*If the maximum time gap is greater than 4 hours OR composes more than 25 percent of the trip, Remove the trip. UNLESS...
*The maximum time gap occurs when the vessel is in port. In these cases, keep the trip
*The maximum time gap is the last record, retain it. This may be due to overland transport to a different port.

We then interpolate the data using the `move` package. This regularizes the data such that we have a VMS ping every hour. After interpolation is done, we re-calculate average speeds for each trip segment, as well as re-join the bathymetry layer.

## Setup and Data Import

Clear workspace
```{r, echo=FALSE,message=FALSE}
library(tidyverse)
library(magrittr)
library(here)
library(lubridate)
library(sf)
library(move)
library(rgdal)

# ggplot theme
plot_theme <-   theme_minimal()+
  theme(text=element_text(family="sans",size=12,color="black"),
        legend.text = element_text(size=14),
        axis.title=element_text(family="sans",size=14,color="black"),
        axis.text=element_text(family="sans",size=8,color="black"),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank())
theme_set(plot_theme)

rm(list=setdiff(ls(),c('process_year','alltime')))

#if needed, process_year
#process_year=2014
```

Read in the filtered VMS data set from the previous step

```{r rawdat}
vms_filtered <- read_rds(here::here('data','processed','matched','filtering',paste0(process_year,'matched_filtered.rds')))

#vms_filtered <- read_rds(paste0("/Users/jameal.samhouri/Documents/RAIMBOW/Processed Data/VMS/",process_year,'matched_filtered.rds'))
```

## Remove Trips with Large Time Gaps

Find trips whose maximum time gap is greater than 4 hours or encompasses more than 25 percent of the trip
NOTE:: Was this 40% before??

```{r}
# random_trip <- vms_filtered %>% filter(TARGET_rev=='DCRB') %>% distinct(Rec_ID) %>% sample_n(3) %>% pull(Rec_ID)

vms_gapfiltered <- vms_filtered %>%
  # filter(Rec_ID %in% random_trip) %>% 
  group_by(Rec_ID) %>% 
  # overall trip duration
  mutate(trip_dur=sum(segment_dur)) %>% 
  # add a sequential record number
  arrange(westcoastdate) %>% 
  mutate(recnum=row_number()) %>% 
  #indicate whether to keep or remove trip based on segment durations
  mutate(keep_remove_timelag=ifelse(max(segment_dur,na.rm=T) > (4*3600) | (segment_dur/trip_dur) > 0.40, "remove", "keep")) %>% 
  #indicate whether the reason for removal was because of the last segment
  mutate(longest_seg=first(recnum,order_by=desc(segment_dur))) %>% 
  mutate(last_seg_longest=longest_seg==max(recnum)) %>% 
  mutate(is_last_seg=ifelse(last_seg_longest&keep_remove_timelag=='remove',TRUE,FALSE)) %>% 
  ungroup()

trips_removed_table <- vms_gapfiltered %>%
  filter(keep_remove_timelag=='remove') %>% 
  dplyr::select(Rec_ID,last_seg_longest,is_last_seg) %>% 
  distinct()

ntottrips <- length(unique(vms_filtered$Rec_ID))
nremovedtrips <- length(unique(trips_removed_table$Rec_ID))
nremovedlastseg <- trips_removed_table %>% filter(is_last_seg) %>% nrow()
```

With these criteria, out of `r ntottrips` unique trips in the filtered dataset, we flagged `r nremovedtrips` for removal, with `r nremovedlastseg` of these because of the last segment in the trip. For now, we instead retain these `r nremovedlastseg` trips for investigation later.

Now we can filter the dataset.

```{r}
vms_gapfiltered %<>%
  # change trips flagged for removal because of last segment to "keep" instead
  mutate(keep_remove_timelag=ifelse(is_last_seg,'keep',keep_remove_timelag)) %>% 
  filter(keep_remove_timelag=='keep')
```

## Interpolate

Interpolate, using package `move`.

Arrange by trip and ascending in time.

```{r}
vms_move <- vms_gapfiltered %>% 
  ungroup() %>% 
  arrange(Rec_ID, UTCDATETIM) %>% 
  distinct(VMS_RECNO,UTCDATETIM,.keep_all = T) %>% 
  mutate(DECLARATIO=na_if(DECLARATIO,'N/A')) %>% 
  #remove_rownames %>%
  as.data.frame()
```

### Create `move` Object

```{r move}
# install.packages("proj4")
# library("proj4")

#some update in the proj_string caused this section to break
#This was the original code
# start.time <- Sys.time()
# movedat <- move(x=vms_move$X_COORD,
#                 y=vms_move$Y_COORD,
#                 time=vms_move$UTCDATETIM,
#                 data=vms_move,
#                 proj=sp::CRS("+proj=utm +north +zone=10 +ellps=WGS84 +datum=WGS84"), #though note that e.g. 2010 HTML doesn't have the '+datum=WGS84' part in this call
#                 animal=vms_move$Rec_ID)
# Sys.time() - start.time




#After various tests, this works now
start.time <- Sys.time()
movedat <- move(x=vms_move$LONGITUDE,
                y=vms_move$LATITUDE,
                time=vms_move$UTCDATETIM,
                data=vms_move,
                proj=sp::CRS("+proj=longlat +datum=WGS84 +no_defs +type=crs"),
                animal=vms_move$Rec_ID)
Sys.time() - start.time

movedatProj <- spTransform(movedat, CRSobj="+proj=utm +zone=10 +datum=WGS84 +units=m +no_defs +type=crs")

```

### Run Interpolation

Starting from a MoveStack object

```{r}
ptm <- proc.time()
#ntrips <- n.indiv(movedat) #change this due to edits made in above section
ntrips <- n.indiv(movedatProj)
interpolated_data <- purrr::map_df(1:ntrips,function(i){

  #tmp_movedat <- movedat[[i]] #change this due to edits made in above section
  tmp_movedat <- movedatProj[[i]]

  inter_movedat <- interpolateTime(x=tmp_movedat, time=as.difftime(60, units="mins"), spaceMethod='euclidean')
  inter_df <- as.data.frame(inter_movedat)
  #clean up the data frame
  inter_df <- inter_df %>%
    dplyr::select(Rec_ID, drvid, UTCDATETIM, X_COORD, Y_COORD, timestamps, coords.x1, coords.x2, sensor) %>% 
    mutate_if(is.factor,as.character)
  if(i%%500==0){
    message("completed interpolation for ", i, " out of ", ntrips, " trips.")
    }
  return(inter_df)
})
tm <- proc.time()-ptm
```

Interpolation took taken `r round(tm[3]/60,2)` minutes to run.

### Integrate Interpolated Data

Rename columns from interpolation so we can re-join the rest of the VMS trip information. For original (non-interpolated) data, we can re-join with times and coordinates. For newly-interpolated data, we define the new time and coordinates and then join the trip-level information.

```{r}
# original:
# orig_vms <- interpolated_data %>%
#   filter(sensor=="unknown") %>% 
#   dplyr::select(-UTCDATETIM,-X_COORD,-Y_COORD) %>% 
#   rename(UTCDATETIM=timestamps,X_COORD=coords.x1,Y_COORD=coords.x2) %>% 
#   left_join(vms_move,by = c("Rec_ID", "drvid", "UTCDATETIM", "X_COORD", "Y_COORD"))

#use this instead
orig_vms <- interpolated_data %>%
  filter(sensor=="unknown") %>% 
  left_join(vms_move,by = c("Rec_ID", "drvid", "UTCDATETIM", "X_COORD", "Y_COORD")) %>% 
  dplyr::select(-UTCDATETIM,-X_COORD,-Y_COORD) %>% 
  rename(UTCDATETIM=timestamps,X_COORD=coords.x1,Y_COORD=coords.x2)



vms_trip_info <- vms_move %>% 
  dplyr::select(-VMS_RECNO,-UTCDATETIM,-LATITUDE,-LONGITUDE,-NGDC_M,-X_COORD,-Y_COORD,-AVG_SPEED,-AVG_COURSE,-westcoastdate,-westcoastdate_notime,-segment_dur,-avg_speed_recalc,-in_port,-recnum,-keep_remove_timelag,-longest_seg,-last_seg_longest,-is_last_seg) %>%
  distinct()


new_vms <- interpolated_data %>% 
  filter(sensor=="interpolateTime")%>% 
  dplyr::select(-UTCDATETIM,-X_COORD,-Y_COORD) %>% 
  rename(UTCDATETIM=timestamps,X_COORD=coords.x1,Y_COORD=coords.x2) %>% 
  left_join(vms_trip_info,by = c("Rec_ID", "drvid"))
```

Create calculable missing columns: west coast dates, latitude, longitude.

```{r}
# west coast dates
new_vms %<>%
  mutate(westcoastdate = with_tz(UTCDATETIM, tzone = "America/Los_Angeles"),
         westcoastdate_notime = as_date(westcoastdate))

# convert UTM x/y coordinates to lat/lon
new_vms_coords <- new_vms %>% 
  st_as_sf(coords=c("X_COORD","Y_COORD"),crs="+proj=utm +north +zone=10 +ellps=WGS84") %>% 
  st_transform(4326) %>% 
  st_coordinates() %>% 
  as_tibble() %>% 
  set_colnames(c('LONGITUDE','LATITUDE'))

# add the new lat/lon into the dataset
new_vms %<>%
  bind_cols(new_vms_coords)
```

Add in VMS Record Numbers for new VMS points

```{r}
new_recnos <- seq(from=(max(vms_move$VMS_RECNO)+10), length.out=nrow(new_vms))
new_vms %<>% mutate(VMS_RECNO = new_recnos)
```

Recombine
```{r}
vms_regular <- bind_rows(orig_vms, new_vms)

# check record numbers to make sure they're unique
length(unique(vms_regular$VMS_RECNO))/length(vms_regular$VMS_RECNO)
```

## Re-calculate Speeds

Finally, just as in the previous step for the non-regularized data, we calculate speeds for each interpolated segment.

```{r}
vms_regular <- vms_regular %>% 
  ungroup() %>% 
  group_by(Rec_ID) %>% 
  # lag latitude and longitude by 1 time step
  mutate(laglon=lag(LONGITUDE,1,order_by=westcoastdate),laglat=lag(LATITUDE,1,order_by=westcoastdate)) %>% 
  # lag time by 1 time step
  mutate(lagdate=lag(westcoastdate,1,order_by=westcoastdate)) %>% 
  # calculate duration since last ping, in seconds
  mutate(segment_dur=as.duration(lagdate %--% westcoastdate)/dseconds()) %>% 
  ungroup()

# Calculate distance (Note: geosphere seems much faster than doing this with sf())
segment_dists <- geosphere::distHaversine(p1=cbind(vms_regular$LONGITUDE, vms_regular$LATITUDE),
                                    p2=cbind(vms_regular$laglon, vms_regular$laglat))

vms_regular %<>% 
  mutate(segment_dist=segment_dists)

# Speed is just segment distance (default in meters) divided by segment duration (in seconds)
vms_regular %<>%
  mutate(avg_speed_recalc=segment_dist/segment_dur) %>% 
  # some calculations will be NaN or Inf because of 0 distance or time. Fix these as zeroes
  mutate(avg_speed_recalc=ifelse(segment_dist==0|segment_dur==0,0,avg_speed_recalc)) %>% 
  # select out columns we don't want (columns that were just used for intermediate calculations)
  dplyr::select(-(recnum:lagdate))
```

## Add Bathymetry Again

We re-match to the bathymetry layer but do NO FILTERING for now.

Read in the bathymetry SpatialGridDataFrame object

```{r}
bathy.grid <- read_rds(here::here('data','raw','vms_composite_bath_spGrid.RDS'))
```

Get bathymetry at VMS data points

```{r}
# tm <- proc.time()
vms_sp <- vms_regular
coordinates(vms_sp) <- c("LONGITUDE", "LATITUDE") 
proj4string(vms_sp)<-proj4string(bathy.grid) <- CRS("+init=epsg:4326") # WGS 84
bathy.points <- over(vms_sp, bathy.grid)$vms_composite_bath
# proc.time()-tm

vms_regular %<>% mutate(NGDC_M = bathy.points)
```

## Save Results

Add a final indicator for whether a point was interpolated or not, then save

```{r}
vms_regular %<>% mutate(is_interpolated=ifelse(sensor=="interpolateTime",1,0)) %>% dplyr::select(-sensor)

write_rds(vms_regular,here::here('data','processed','matched','interpolation',paste0(process_year,'interpolated.rds')))
```

